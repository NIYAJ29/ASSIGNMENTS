{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c30da1-d364-49ea-a39e-98224b674385",
   "metadata": {},
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
    "an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdd552b-f8d4-4cb3-85c4-7e4349ab5e10",
   "metadata": {},
   "source": [
    "The Probability Mass Function (PMF) and Probability Density Function (PDF) are two important concepts in probability theory and statistics.\n",
    "\n",
    "A Probability Mass Function (PMF) is a function that maps each possible outcome of a discrete random variable to its probability. In other words, the PMF gives the probability of each possible value that a discrete random variable can take. The PMF is often denoted by P(X = x), where X is the random variable and x is one of its possible values.\n",
    "\n",
    "For example, consider a six-sided die. The PMF of this die would give the probability of rolling each of the possible numbers on the die. If we let X be the random variable that represents the number rolled on the die, then the PMF of X would be:\n",
    "\n",
    "P(X = 1) = 1/6\n",
    "\n",
    "P(X = 2) = 1/6\n",
    "\n",
    "P(X = 3) = 1/6\n",
    "\n",
    "P(X = 4) = 1/6\n",
    "\n",
    "P(X = 5) = 1/6\n",
    "\n",
    "P(X = 6) = 1/6\n",
    "\n",
    "Note that the sum of all the probabilities in the PMF must equal 1.\n",
    "\n",
    "A Probability Density Function (PDF) is a function that describes the relative likelihood of a continuous random variable taking on a certain value. The PDF is often denoted by f(x), where x is the value of the continuous random variable.\n",
    "\n",
    "For example, consider a random variable X that represents the height of adult males in a population. The PDF of X would give the relative likelihood of a male being a certain height. The PDF might look something like this:\n",
    "\n",
    "f(x) = 0.4*exp(-(x-70)^2/100)\n",
    "\n",
    "where x is the height in inches, and the function f(x) describes the relative likelihood of a male having that height. Note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6e6f25-fb8e-41ea-823c-831927b43209",
   "metadata": {},
   "source": [
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c6e2a-ee92-47b3-93a8-924aa42023d9",
   "metadata": {},
   "source": [
    "A Cumulative Density Function (CDF) is a function that gives the probability that a random variable X is less than or equal to a certain value x. In other words, the CDF gives the cumulative distribution of the random variable X.\n",
    "\n",
    "The CDF of a discrete random variable X can be defined as:\n",
    "\n",
    "F(x) = P(X <= x)\n",
    "\n",
    "where x is a specific value of X. The CDF of a continuous random variable X can be defined as:\n",
    "\n",
    "F(x) = integral from -infinity to x of f(t) dt\n",
    "\n",
    "where f(x) is the probability density function of X.\n",
    "\n",
    "For example, consider a continuous random variable X that represents the height of adult males in a population. The CDF of X would give the probability that a male is less than or equal to a certain height. The CDF might look something like this:\n",
    "\n",
    "F(x) = integral from -infinity to x of f(t) dt\n",
    "\n",
    "where f(x) is the probability density function of X, which might be a normal distribution with a mean of 70 inches and a standard deviation of 3 inches.\n",
    "\n",
    "The CDF is used in many areas of statistics and probability theory. For example, it can be used to calculate probabilities of events such as finding the probability that a male is taller than a certain height, or the probability that a stock price will increase by a certain amount over a given time period. It is also used in hypothesis testing and confidence intervals, where the CDF is used to calculate the probability of observing a certain outcome if a null hypothesis is true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62b0237-8adf-4f46-ad30-1c0b5555e55a",
   "metadata": {},
   "source": [
    "Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425bf80d-2dfd-478f-b3f8-10442ffeff3a",
   "metadata": {},
   "source": [
    "The normal distribution is a commonly used probability distribution in statistics and probability theory. It is used to model many real-world phenomena that exhibit a bell-shaped curve, such as heights and weights of individuals, IQ scores, and errors in measurements.\n",
    "\n",
    "Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "The distribution of test scores: If a large number of students take a standardized test, the distribution of their scores is likely to be approximately normal.\n",
    "\n",
    "The distribution of heights and weights: The heights and weights of individuals in a population often follow a normal distribution.\n",
    "\n",
    "The distribution of errors in measurements: If a measurement process has a small random error, the distribution of those errors is often well approximated by a normal distribution.\n",
    "\n",
    "The normal distribution is characterized by two parameters: its mean and its standard deviation. The mean (μ) is the center of the distribution, while the standard deviation (σ) determines the spread of the distribution.\n",
    "\n",
    "If the mean is increased, the entire distribution will shift to the right. If the mean is decreased, the distribution will shift to the left.\n",
    "\n",
    "If the standard deviation is increased, the distribution will become wider and flatter. If the standard deviation is decreased, the distribution will become narrower and taller.\n",
    "\n",
    "The combination of the mean and standard deviation determines the shape of the normal distribution. The more spread out the distribution, the flatter it becomes. Conversely, the more concentrated the distribution, the taller it becomes. A normal distribution with a small standard deviation is often called a \"narrow\" or \"tight\" distribution, while a normal distribution with a large standard deviation is often called a \"wide\" or \"loose\" distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf33d69-17f1-4452-b8d6-8da611a7d175",
   "metadata": {},
   "source": [
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal\n",
    "Distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e02614-8478-4ffd-8923-0911d96054d1",
   "metadata": {},
   "source": [
    "The Normal Distribution is important in statistics and probability theory because it provides a mathematical model that can be used to approximate many real-world phenomena. It is often used as a benchmark for comparison with other distributions, and many statistical tests and models rely on the assumption that the data follows a normal distribution.\n",
    "\n",
    "Here are a few examples of real-life situations where the normal distribution is commonly observed:\n",
    "\n",
    "Heights and weights of individuals: The distribution of heights and weights of individuals in a population often follows a normal distribution. This makes it a useful model for studying things like the average height or weight of a population, or the probability of a person being a certain height or weight.\n",
    "\n",
    "IQ scores: The distribution of IQ scores in a population also tends to follow a normal distribution, with the mean score set at 100 and a standard deviation of 15.\n",
    "\n",
    "Errors in measurements: When making measurements or performing experiments, there is often a small amount of random error. The distribution of these errors is often well approximated by a normal distribution, which allows us to model the likelihood of obtaining a certain result.\n",
    "\n",
    "Stock market returns: The returns of many stocks tend to follow a normal distribution, which allows us to model the likelihood of obtaining a certain return or the volatility of a stock.\n",
    "\n",
    "Blood pressure: The distribution of blood pressure in a population tends to follow a normal distribution, which can be used to study the average blood pressure levels and the likelihood of individuals having high or low blood pressure.\n",
    "\n",
    "In summary, the normal distribution is an important tool in statistics and probability theory because it provides a mathematical model that can be used to approximate many real-world phenomena. By understanding the properties of the normal distribution, we can make better predictions and better understand the likelihood of certain events or outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7331bd5b-9647-4c3f-a712-0709ae3b3529",
   "metadata": {},
   "source": [
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
    "Distribution and Binomial Distribution?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1a6873-a7b0-43d6-a323-91aead71abb8",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a probability distribution that models a single trial of a random experiment with only two possible outcomes, typically labeled as success and failure. The distribution is named after the Swiss mathematician Jacob Bernoulli.\n",
    "\n",
    "The Bernoulli distribution is characterized by a single parameter, p, which is the probability of success. The probability of failure is therefore 1 - p. The probability mass function (PMF) of the Bernoulli distribution is given by:\n",
    "\n",
    "P(X = 1) = p\n",
    "P(X = 0) = 1 - p\n",
    "\n",
    "where X is a random variable that takes the value 1 if the experiment is a success and 0 if the experiment is a failure.\n",
    "\n",
    "An example of a Bernoulli experiment is flipping a coin, where heads is a success and tails is a failure. If p is the probability of getting heads, then the Bernoulli distribution can be used to model the outcome of a single coin flip.\n",
    "\n",
    "The Binomial distribution, on the other hand, models the number of successes in a fixed number of independent Bernoulli trials. The Binomial distribution is characterized by two parameters: the number of trials n and the probability of success p. The probability mass function (PMF) of the Binomial distribution is given by:\n",
    "\n",
    "P(X = k) = (n choose k) * p^k * (1 - p)^(n-k)\n",
    "\n",
    "where X is the random variable representing the number of successes in n independent Bernoulli trials, and k is a particular number of successes (0 <= k <= n).\n",
    "\n",
    "The main difference between the Bernoulli and Binomial distributions is that the Bernoulli distribution models a single trial with two possible outcomes, while the Binomial distribution models the number of successes in a fixed number of independent Bernoulli trials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e904a618-c921-4ec2-a255-d84e3b1fe935",
   "metadata": {},
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "than 60? Use the appropriate formula and show your calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696c5186-b5b6-46e5-b74d-a59ccca4c486",
   "metadata": {},
   "source": [
    "The z-score formula is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "z = (60 - 50) / 10\n",
    "\n",
    "z = 1\n",
    "\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from the dataset will be greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b71feef-2816-43e1-ae9b-7d2d06b2c85b",
   "metadata": {},
   "source": [
    "Q7: Explain uniform Distribution with an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c32ebb9-20c0-463d-8679-f80400d76c0a",
   "metadata": {},
   "source": [
    "The uniform distribution is a probability distribution that models the situation where all outcomes in a given range are equally likely. The distribution is characterized by two parameters: a and b, which represent the minimum and maximum values of the range.\n",
    "\n",
    "The probability density function (PDF) of the uniform distribution is given by:\n",
    "\n",
    "f(x) = 1 / (b - a), a <= x <= b\n",
    "f(x) = 0, otherwise\n",
    "\n",
    "This means that the probability of any value in the range [a, b] is the same, and the probability of any value outside of that range is zero.\n",
    "\n",
    "An example of the uniform distribution is rolling a fair six-sided die. In this case, the minimum value of the range is a = 1 and the maximum value is b = 6. Each possible outcome (1, 2, 3, 4, 5, or 6) is equally likely, so the probability of rolling any one number is 1/6.\n",
    "\n",
    "Another example is choosing a random number between 0 and 1 using a random number generator. In this case, the minimum value of the range is a = 0 and the maximum value is b = 1. Any number between 0 and 1 is equally likely, so the probability of selecting any one value is 1/(1-0) = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf6db07-92bf-4df0-b678-2bff89db23e4",
   "metadata": {},
   "source": [
    "Q8: What is the z score? State the importance of the z score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264dfe6b-3125-4881-a708-d3dac69df7b2",
   "metadata": {},
   "source": [
    "The z-score, also known as the standard score, is a statistical measure that indicates how many standard deviations an observation or data point is above or below the mean of a normally distributed dataset. It is calculated using the following formula:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where x is the value of the observation or data point, μ is the mean of the dataset, and σ is the standard deviation of the dataset.\n",
    "\n",
    "The z-score is important because it allows us to standardize different datasets and compare observations or data points that are measured in different units or have different scales. By converting all data points to a standard scale, we can make meaningful comparisons and draw conclusions from the data.\n",
    "\n",
    "Some of the important uses of the z-score include:\n",
    "\n",
    "Identifying outliers: Observations with a z-score greater than 3 or less than -3 are often considered outliers and may be investigated further.\n",
    "\n",
    "Hypothesis testing: The z-score is used in hypothesis testing to determine whether an observation or sample mean is statistically different from the population mean.\n",
    "\n",
    "Quality control: The z-score is used in quality control to monitor process performance and detect deviations from the target.\n",
    "\n",
    "Standardization: The z-score is used to standardize different datasets, allowing for comparisons between datasets that may have different means and standard deviations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fc22e0-3e3c-4f05-99dd-1323b86c8015",
   "metadata": {},
   "source": [
    "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26490364-7abb-42f8-a0ae-fc5fcc747416",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in probability theory and statistics that states that the sample means of a large number of independent and identically distributed (i.i.d.) random variables, regardless of their underlying distribution, will be normally distributed.\n",
    "\n",
    "More specifically, the Central Limit Theorem states that if we take a random sample of size n from any population with a finite mean and standard deviation, then the distribution of the sample means will be approximately normal, regardless of the shape of the population distribution. As the sample size increases, the distribution of the sample means approaches a normal distribution with mean equal to the population mean and standard deviation equal to the population standard deviation divided by the square root of the sample size.\n",
    "\n",
    "The significance of the Central Limit Theorem is that it allows us to make inferences about population parameters based on sample statistics. For example, if we want to estimate the mean or variance of a population, we can take a random sample and use the sample mean or sample variance as an estimate of the population mean or population variance. The Central Limit Theorem assures us that if the sample size is large enough, the distribution of the sample mean will be approximately normal, and we can use the properties of the normal distribution to make statistical inferences.\n",
    "\n",
    "The Central Limit Theorem is also important in hypothesis testing, where we compare a sample statistic to a population parameter to make conclusions about the population. In this context, the Central Limit Theorem allows us to use the normal distribution to calculate probabilities and make decisions about whether to reject or fail to reject a null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec6ff9e-581f-49b9-b8cc-2d627651bf3e",
   "metadata": {},
   "source": [
    "Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2764de-0d05-4fe0-911d-0f1a62f1fa71",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in probability theory and statistics that states that the sample means of a large number of independent and identically distributed (i.i.d.) random variables, regardless of their underlying distribution, will be normally distributed. However, the CLT relies on several assumptions:\n",
    "\n",
    "Independence: The observations in the sample must be independent of each other.\n",
    "\n",
    "Sample size: The sample size n should be sufficiently large, typically greater than or equal to 30. However, this number can vary depending on the population distribution.\n",
    "\n",
    "Population distribution: The population distribution should have a finite mean and variance. If the population is highly skewed or has heavy tails, a larger sample size may be required to approximate the normal distribution.\n",
    "\n",
    "Random sampling: The sample must be a random sample drawn from the population of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6a6722-a5c7-4137-85c8-3a50a34a9dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
